% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/query.r
\name{feature_query}
\alias{feature_query}
\title{Find tokens using a Lucene-like search query}
\usage{
feature_query(tc, keyword, condition = "", code = "", feature = "word",
  default_window = NA, condition_once = FALSE, keyword_filter = NULL)
}
\arguments{
\item{keyword}{The keyword part of the query, see explanation in query_tutorial markdown or in details below}

\item{condition}{The condition part of the query, see explanation in query_tutorial markdown or in details below}

\item{code}{The code given to the tokens that match the query (usefull when looking for multiple queries)}

\item{default_window}{Determines the default word distance of the condition terms to the keyword (thus, if no specific word distance is set with the ~ symbol)}

\item{condition_once}{logical. If TRUE, then if an keyword satisfies its conditions once in an article, all keywords within that article are coded.}

\item{keyword_filter}{A logical vector that indicates which tokens can match an keyword. Can for instance be used to only select tokens that are proper names (using POS tagging) when looking for people.}

\item{tokenlist}{a tokenlist object, created with the asTokenlist() function.}

\item{presorted}{The data has to be sorted on order(doc_id, position). If this is already the case, presorted can be set to TRUE to save time (which is usefull when testing many individual queries for large tokenlists)}

\item{doc_id}{A vector with document ids. By default the 'doc_id' column of the tokenlist. This parameter can be used if you do not use a default tokenlist, or want to use an alternative column (e.g., paragraph, sentence)}

\item{position}{A vector with the positions of words. By default the 'position' column of the tokenlist.}

\item{word}{A vector with words. By default the 'word' column of the tokenlist. This parameter can be used if you do not use a default tokenlist, or want to use an alternative column (e.g., stem, lemma)}
}
\value{
a data.frame containing the words that match the query, and their locations in the tokenlist
}
\description{
Search tokens in a tokenlist using a query that consists of an keyword, and optionally a condition. For a detailed explanation of the query language please consult the query_tutorial markdown file. For a quick summary see the details below.
}
\details{
Brief summary of the query language

The keyword:
\itemize{
   \item{is the actual feature that has to be found in the token}
   \item{can contain multiple words with OR statement (and empty spaces are also considered OR statements)}
   \item{CANNOT contain AND or NOT statements (this is what the condition is for)}
   \item{accepts the ? wildcard, which means that any single character can be used in this place}
   \item{accepts the * wildcard, which means that any number of characters can be used in this place}
 }

The condition:
\itemize{
   \item{has to be TRUE for the keyword to be accepted. Thus, if a condition is given, the query can be interpreted as: keyword AND condition}
   \item{can contain complex boolean statements, using AND, OR and NOT statements, and using parentheses}
   \item{accepts the ? and * wildcards}
   \item{can be specified for a maximum word distance of the keyword. The terms in the condition are looked up within this word distance. The default word distance can be given with the default_window parameter. More specifically, individual terms can be given a custom word distance using the ~ symbol, where "word~50" means that "word" is looked up within 50 words of the keyword. If a default_window is used, it is also possible to ignore the word distance for specific terms by using word~d (where d stands for document).}
}

Parameters:
\itemize{
   \item{default_window -> determines the default word distance of the condition terms to the keyword (thus, if no specific word distance is set with the ~ symbol)}
   \item{condition_once -> if TRUE, then if the condition is satisfied at least once in an article, all occurences of the keyword are accepted. }
}
}

